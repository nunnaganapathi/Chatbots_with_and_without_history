{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "hr3tdAHIMPpE",
        "outputId": "dcf961b3-5a22-42c6-9859-f1086c7f482e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "68e707babf4a448cae65d6d7d80778c3",
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axnTgvb0MVm6",
        "outputId": "1b374e4a-888f-41b1-8c51-206bdbd3f2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start chatting with the bot (type 'quit' to stop)!\n",
            "User: hi\n",
            "Bot: Hello! How can I assist you today?\n",
            "User: who is trump\n",
            "Bot: Donald Trump is a businessman, television personality, and politician who served as the 45th President of the United States from 2017 to 2021. He is known for his controversial statements and policies during his time in office.\n",
            "User: where he stays\n",
            "Bot: I'm sorry, could you please provide more context or information so that I can assist you better?\n",
            "User: quit\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "\n",
        "openai.api_key = (\"*****************\")\n",
        "  # Replace with your OpenAI API key\n",
        "\n",
        "def chatbot():\n",
        "    # Only have a basic system message to initialize the context\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "\n",
        "    # Keep repeating the following\n",
        "    while True:\n",
        "        # Prompt user for input\n",
        "        message = input(\"User: \")\n",
        "\n",
        "        # Exit program if user inputs \"quit\"\n",
        "        if message.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        # Add the user message to the context\n",
        "        messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        # Request gpt-3.5-turbo for chat completion with only the current message\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        # Get the assistant's response\n",
        "        chat_message = response['choices'][0]['message']['content']\n",
        "        print(f\"Bot: {chat_message}\")\n",
        "\n",
        "        # After each response, clear the history to make it stateless (no memory of previous chats)\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]  # Reset history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Start chatting with the bot (type 'quit' to stop)!\")\n",
        "    chatbot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0saiGdK9LT6",
        "outputId": "d876874f-ba48-42fd-f104-f9c9664aa1ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start chatting with the bot (type 'quit' to stop)!\n",
            "User: hi\n",
            "Bot: Hello! How can I assist you today?\n",
            "User: who is trump\n",
            "Bot: Donald Trump is an American businessman, television personality, and politician who served as the 45th President of the United States from 2017 to 2021. He was also a candidate for the 2016 and 2020 presidential elections.\n",
            "User: where he stays\n",
            "Bot: Donald Trump's primary residence is his private estate and club, Mar-a-Lago, located in Palm Beach, Florida.\n",
            "User: quit\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = (\"****************\")\n",
        "\n",
        "def chatbot():\n",
        "  # Create a list to store all the messages for context\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "  ]\n",
        "\n",
        "  # Keep repeating the following\n",
        "  while True:\n",
        "    # Prompt user for input\n",
        "    message = input(\"User: \")\n",
        "\n",
        "    # Exit program if user inputs \"quit\"\n",
        "    if message.lower() == \"quit\":\n",
        "      break\n",
        "\n",
        "    # Add each new message to the list\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Request gpt-3.5-turbo for chat completion\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=messages\n",
        "    )\n",
        "\n",
        "    # Print the response and add it to the messages list\n",
        "    chat_message = response['choices'][0]['message']['content']\n",
        "    print(f\"Bot: {chat_message}\")\n",
        "    messages.append({\"role\": \"assistant\", \"content\": chat_message})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"Start chatting with the bot (type 'quit' to stop)!\")\n",
        "  chatbot()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
